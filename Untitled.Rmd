---
title: "hw6"
author: "Jiabei Wang"
date: "2018/11/26"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(rvest)
library(purrr)
library(stringr)
library(broom)
library(modelr)
library(dplyr)
library(leaps)
library(mgcv)
knitr::opts_chunk$set(echo = TRUE)
```

problem1
```{r}
city_homicides = read_csv(file = "./homicide-data.csv") %>%
  janitor::clean_names()
city_homicides = city_homicides %>%
  mutate(city_state = str_c(city, state, sep = "_")) %>%
  filter(!(city_state == "Dallas_TX" | city_state == "Phoenix_AZ" | city_state == "Kansas City_MO" | city_state == "Tulsa_AL")) %>%
  mutate(resolved = as.numeric(disposition == "Closed by arrest"),
         victim_age = as.numeric(victim_age)) %>%
mutate(victim_race = fct_relevel(ifelse(victim_race == "White", "white", "non-white"), "white")) %>%
mutate(victim_race = fct_relevel(victim_race, "White")) 
```
  
  
```{r}
baltimore = city_homicides %>%
  filter(city == "Baltimore")

fit_logistic = baltimore %>%
  glm(resolved ~victim_age + victim_sex + victim_race, data = ., family = binomial()) 

  fit_logistic %>%
broom::tidy() %>%
mutate(OR = exp(estimate), 
  lower_bound = exp(estimate - std.error*1.96),
         upper_bound = exp(estimate + std.error*1.96)) %>%
  select(term, log_OR = estimate, OR, lower_bound, upper_bound, p.value) %>% 
  knitr::kable(digits = 3)
```

The odds ratio for nonwhite is 0.441, and the 95% confidence interval is (0.313, 0.620)

```{r}
city_data = city_homicides %>%
  group_by(city_state) %>%
  nest() 
city_data = city_data %>%  
mutate(model_result = map(data, ~glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()))) %>%
  select(-data) %>%
   mutate (model_result = map(model_result, broom::tidy)) %>%
     unnest(model_result) %>%
filter(term == "victim_racenon-white") %>% 
  mutate(OR = exp(estimate),
         lower_bound = exp(estimate - std.error*1.96),
         upper_bound = exp(estimate + std.error*1.96)) 

```

```{r}
city_data%>%
  mutate(city_state = fct_reorder(city_state, OR)) %>%
ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = lower_bound, ymax = upper_bound)) +  
    theme(text = element_text(size = 6), 
          axis.text.x = element_text(angle = 90),
          legend.key.size= unit(0.05,"cm")) +

    labs(title = "Estimate OR and CI Across Cities",
    x = "city_state",
    y = "Estimated OR"
  ) 

```

problem 2
```{r}
Birthweight_data = read_csv(file = "./birthweight.csv") %>%
mutate(babysex = as.factor(babysex),
frace = as.factor(frace),
malformn = as.factor(malform),
mrace = as.factor(mrace))

##Build Model
mult.fit <- lm(bwt ~ ., data=Birthweight_data)
step(mult.fit, direction='backward')

```
I use the stepwise backward method to build the model.
```{r}
build_own_model = lm(bwt ~ babysex + bhead + blength + delwt +  
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = Birthweight_data) 

build_own_model %>%
summary()

build_own_model %>%
  broom::tidy()

Birthweight_data %>% 
  add_residuals(build_own_model) %>% 
  add_predictions(build_own_model) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point()

```

```{r}
##two other models
model1 = lm(bwt~blength + gaweeks, data = Birthweight_data)

model1 %>%
summary()
model1 %>%
broom::tidy()

model2 = lm(bwt~bhead + blength + babysex + bhead*babysex*blength, data = Birthweight_data)

model2 %>%
summary()
model2 %>%
broom::tidy()

```
The Rsquare of our own designed model is 0.7173, and the Rsquare for the other two is 0.5767 and  0.6844 respectively. Since Rsquare explains the percentage of explained variation, the higher is better. Thus, our fitted model is better than the other two. 

```{r}
set.seed(1)
cv_df = crossv_mc(Birthweight_data, 100, test =0.2) %>%
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))
```

```{r}
cv_df = 
  cv_df %>% 
  mutate(model1    = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt +  gaweeks + mheight + mrace + parity + ppwt + smoken, data =  Birthweight_data)),
        model2 = map(train, ~lm(bwt~blength + gaweeks, data = Birthweight_data)), 
        model3 = map(train, ~lm(bwt~bhead + blength + babysex + bhead*babysex*blength, data = Birthweight_data))) %>% 
  mutate(rmse_1    = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
         rmse_2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
         rmse_3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y)))
```

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() + ggtitle("rmse for for each model ")
```

The model lie at the lowest level has the relatively lowest rmse. Since we want to minimize rmse, the first model is the best. 

